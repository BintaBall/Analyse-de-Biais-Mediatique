# Projet d'Analyse des Discours MÃ©diatiques

## ðŸ“‹ Table des MatiÃ¨res
1. [ðŸŽ¯ PrÃ©sentation du Projet](#-prÃ©sentation-du-projet)
2. [ðŸ“Š DonnÃ©es et MÃ©thodologie](#-donnÃ©es-et-mÃ©thodologie)
3. [ðŸ› ï¸ Architecture Technique](#ï¸-architecture-technique)
4. [ðŸ“ˆ RÃ©sultats et Analyses](#-rÃ©sultats-et-analyses)
5. [ðŸš€ DÃ©ploiement et Utilisation](#-dÃ©ploiement-et-utilisation)
6. [ðŸ”® Perspectives et AmÃ©liorations](#-perspectives-et-amÃ©liorations)

## PrÃ©sentation du Projet

### Contexte
Ce projet vise Ã  analyser les discours mÃ©diatiques Ã  grande Ã©chelle en utilisant des techniques avancÃ©es de Natural Language Processing (NLP). L'objectif est d'identifier des patterns, des biais potentiels et des Ã©volutions dans le traitement mÃ©diatique de l'information sur une pÃ©riode de 9 ans.

### Objectifs
- **Analyser** 35,468 articles du Huffington Post (2014-2022)
- **Identifier** des clusters sÃ©mantiques dans les discours
- **DÃ©tecter** des thÃ¨mes rÃ©currents et leur Ã©volution temporelle
- **Ã‰valuer** le ton et le sentiment des articles
- **CrÃ©er** un dashboard interactif pour l'exploration des rÃ©sultats

### Technologies UtilisÃ©es
- **NLP** : DistilBERT, LDA, TF-IDF
- **Clustering** : K-means, GMM, HDBSCAN
- **Visualisation** : Plotly, Streamlit, Matplotlib
- **Backend** : PyTorch, Scikit-learn, Pandas
- **DÃ©ploiement** : Streamlit Cloud

## ðŸ“Š DonnÃ©es et MÃ©thodologie

### Sources de DonnÃ©es
```
Source : Huffington Post (HuffPost)
PÃ©riode : Avril 2014 - Septembre 2022
Volume : 35,468 articles
Variables : Titre, contenu, date, source
```

### Pipeline d'Analyse
```
1. Collecte & Nettoyage â†’ 2. Embeddings BERT â†’ 3. Clustering
       â†“                         â†“                   â†“
   Texte brut           ReprÃ©sentation vectorielle   Groupes sÃ©mantiques
       â†“                         â†“                   â†“
4. Topic Modeling â†’ 5. Analyse Sentiment â†’ 6. Visualisation
       â†“                   â†“                   â†“
   ThÃ¨mes identifiÃ©s   Ton des articles   Dashboard interactif
```

### MÃ©thodes de Clustering
- **K-means** (k=5) : MÃ©thode principale avec silhouette score 0.035
- **Gaussian Mixture Models** : Alternative pour distributions complexes
- **HDBSCAN** : Clustering basÃ© sur la densitÃ©
- **MiniBatch K-means** : Version optimisÃ©e pour grandes donnÃ©es

## ðŸ› ï¸ Architecture Technique

### Structure du Projet
```
biais_mediatique/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # DonnÃ©es brutes (non versionnÃ©es)
â”‚   â””â”€â”€ processed/        # DonnÃ©es transformÃ©es
â”‚       â”œâ”€â”€ news_clean.csv
â”‚       â”œâ”€â”€ news_embeddings.pt
â”‚       â”œâ”€â”€ news_with_discourse.csv
â”‚       â””â”€â”€ visualizations/
â”œâ”€â”€ src/        
â”‚   â”œâ”€â”€ models/          # GÃ©nÃ©ration d'embeddings
â”‚   â”‚   â””â”€â”€ distilbert_embeddings.py
â”‚   â”œâ”€â”€ analysis/        # Analyses statistiques
â”‚   â”‚   â”œâ”€â”€ discourse_analysis.py
â”‚   â”‚   â””â”€â”€ comparative_analysis.py
â”‚   â”œâ”€â”€ app/   # Dashboard
â”‚   â”‚   â””â”€â”€ streamlit_app.py
â”‚   â””â”€â”€ reporting/       # GÃ©nÃ©ration de rapports
â”œâ”€â”€ requirements.txt     # DÃ©pendances Python
â”œâ”€â”€ runtime.txt         # Version Python pour dÃ©ploiement
â””â”€â”€ README.md          # Documentation
```

### ModÃ¨le NLP : DistilBERT
- **ModÃ¨le** : `distilbert-base-uncased`
- **Embeddings** : 768 dimensions par article
- **Tokenization** : Longueur maximale = 128 tokens
- **Batch size** : 32 (optimisÃ© pour CPU/GPU modeste)

### MÃ©triques d'Ã‰valuation
```python
# Scores obtenus
silhouette_score = 0.035      # Structure faible mais discernable
sentiment_mean = 0.238        # Ton globalement positif
cluster_balance = "Relativement Ã©quilibrÃ©"
```

## RÃ©sultats et Analyses

### 1. Structure Temporelle
```
ðŸ“… Distribution Annuelle (articles)
2014: 2,853    2015: 4,655    2016: 8,179
2017: 11,210   2018: 4,087    2019: 1,265
2020: 1,113    2021: 1,291    2022: 815

Pic d'activitÃ© : 2017 (11,210 articles)
Chute post-2017 : -88.8% en 2022
```

### 2. Clusters SÃ©mantiques (5 groupes)
```
ðŸŽ¯ Cluster 0 : 23.0% des articles
ðŸŽ¯ Cluster 1 : 14.3% des articles  
ðŸŽ¯ Cluster 2 : 22.8% des articles
ðŸŽ¯ Cluster 3 : 27.2% des articles (dominant)
ðŸŽ¯ Cluster 4 : 12.7% des articles

ðŸ“ˆ Ã‰volution : Cluster 3 devient progressivement dominant Ã  partir de 2016
```

### 3. ThÃ¨mes IdentifiÃ©s (LDA - 8 topics)
```
ðŸ“š ThÃ¨me 0 : SociÃ©tÃ© et vie quotidienne (people, women, school, right)
ðŸ“š ThÃ¨me 1 : Affaires internationales (military, united states, world)
ðŸ“š ThÃ¨me 2 : SantÃ© et politique (health care, republicans, senate)
ðŸ“š ThÃ¨me 3 : Faits divers (police, city, according)
ðŸ“š ThÃ¨me 4 : Justice et droits (court, justice, federal)
ðŸ“š ThÃ¨me 5 : Ã‰lections (clinton, voters, democratic, election)
ðŸ“š ThÃ¨me 6 : Trump - campagne (trump, donald, campaign)
ðŸ“š ThÃ¨me 7 : Trump - prÃ©sidence (president, white house, obama)
```

### 4. Analyse de Sentiment
```
ðŸ˜Š Score moyen : 0.238 (positif)
RÃ©partition :
   â€¢ Positif (>0.1) : 56.9% des articles
   â€¢ NÃ©gatif (<-0.1) : 22.4% des articles  
   â€¢ Neutre : 20.8% des articles

Variation temporelle : Relativement stable sur la pÃ©riode
```

### 5. PersonnalitÃ©s MentionnÃ©es
```
Top 10 des personnalitÃ©s :
1. Trump : 51.9% des articles
2. Obama : 28.5%
3. Clinton : 19.9%
4. Sanders : 9.0%
5. Biden : 4.9%
6. Pence : 4.1%
7. Putin : 4.1%
8. Johnson : 3.3%
9. Harris : 2.4%
10. Pelosi : 2.1%
```

### 6. ComplexitÃ© Linguistique
```
 Statistiques moyennes :
   â€¢ Mots par article : 763 mots
   â€¢ Longueur moyenne des mots : 5.0 caractÃ¨res
   â€¢ ComplexitÃ© par cluster : 703-824 mots/article

Cluster 3 : Articles les plus longs (824 mots en moyenne)
```

##  DÃ©ploiement et Utilisation

### Installation Locale
```bash
# 1. Cloner le repository
git clone[ https://github.com/votre-nom/biais_mediatique.git](https://github.com/BintaBall/Analyse-de-Biais-Mediatique.git)
cd biais_mediatique

# 2. CrÃ©er l'environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows

# 3. Installer les dÃ©pendances
pip install -r requirements.txt

# 4. ExÃ©cuter le pipeline complet
python src/models/distilbert_embeddings.py
python src/analysis/discourse_analysis.py
python src/analysis/comparative_analysis.py

# 5. Lancer le dashboard
streamlit run src/visualization/streamlit_app.py
```

### DÃ©ploiement Streamlit Cloud
1. **Pousser le code sur GitHub**
2. **Se connecter Ã  [share.streamlit.io](https://share.streamlit.io)**
3. **Configurer l'application :**
   - Repository : `[BintaBall/Analyse-de-Biais-Mediatique](https://github.com/BintaBall/Analyse-de-Biais-Mediatique.git)`
   - Branch : `main`
   - Main file : `src/app/streamlit_app.py`
4. **L'application est disponible Ã  :**
   ```
    https://analyse-de-biais-mediatique-bl9pdwfkdrprvvnfdkqw7s.streamlit.app/  
    ```

### Utilisation du Dashboard
Le dashboard offre 5 onglets interactifs :

1. **ðŸ“ˆ Distribution** : Clusters et thÃ¨mes
2. **ðŸ“… Temporel** : Ã‰volution 2014-2022  
3. **ðŸ“š ThÃ¨mes** : Description des 8 thÃ¨mes identifiÃ©s
4. **ðŸ˜Š Sentiment** : Analyse du ton des articles
5. **ðŸ” Exploration** : Recherche par mot-clÃ©

## Perspectives et AmÃ©liorations

### Limitations Actuelles
1. **Score silhouette faible** (0.035) : Les clusters ne sont pas bien sÃ©parÃ©s
2. **Source unique** : Seulement HuffPost analysÃ©
3. **PÃ©riode limitÃ©e** : 2014-2022
4. **ComplexitÃ© computationnelle** : GÃ©nÃ©ration des embeddings longue

### AmÃ©liorations Possibles

#### 1. Extension des DonnÃ©es
```python
# Ajouter d'autres sources
sources_additionnelles = [
    "New York Times",
    "Washington Post", 
    "Fox News",
    "CNN",
    "BBC"
]

# Ã‰tendre la pÃ©riode
periode_etendue = "2000-2023"
```

#### 2. AmÃ©liorations Techniques
- **ModÃ¨les avancÃ©s** : RoBERTa, DeBERTa, GPT embeddings
- **Clustering amÃ©liorÃ©** : UMAP + HDBSCAN
- **Topic modeling** : BERTopic, Top2Vec
- **Analyse multimodale** : Images + texte

#### 3. FonctionnalitÃ©s SupplÃ©mentaires
```python
fonctionnalites_futures = [
    "DÃ©tection de fake news",
    "Analyse comparative droite/gauche", 
    "PrÃ©diction d'engagement (likes, shares)",
    "Alertes en temps rÃ©el sur tendances",
    "API REST pour intÃ©gration"
]
```

#### 4. DÃ©ploiement Production
- **Conteneurisation** : Docker + Kubernetes
- **Base de donnÃ©es** : PostgreSQL/Elasticsearch
- **Orchestration** : Airflow/Prefect
- **Monitoring** : Prometheus + Grafana

### Applications Pratiques
1. **Journalisme** : DÃ©tection de biais, analyse de couverture
2. **AcadÃ©mique** : Ã‰tudes des discours mÃ©diatiques
3. **Business Intelligence** : Veille mÃ©diatique automatisÃ©e
4. **Ã‰ducation** : Outil pÃ©dagogique sur les mÃ©dias

##  Conclusion

### Contributions Principales
1. **Pipeline complet** de collecte Ã  visualisation
2. **Analyse Ã  grande Ã©chelle** de 35k+ articles
3. **MÃ©thodes multiples** : BERT embeddings + clustering + topic modeling
4. **Dashboard interactif** accessible en ligne
5. **Documentation technique** complÃ¨te et reproductible

### Insights ClÃ©s
- **ContinuitÃ© sÃ©mantique** plutÃ´t que silos distincts
- **Ã‰volution temporelle** marquÃ©e (pic 2017, chute postÃ©rieure)
- **Ton global positif** mais nuances selon les thÃ¨mes
- **PrÃ©dominance de Trump** dans le discours mÃ©diatique
- **ComplexitÃ© variable** selon les types d'articles

---
*Ce projet a Ã©tÃ© dÃ©veloppÃ© dans le cadre d'une analyse NLP avancÃ©e des discours mÃ©diatiques. Les mÃ©thodes et rÃ©sultats sont entiÃ¨rement reproductibles avec le code fourni.*